\chapter{Capsule Network Architectures}\label{chapter:capsules}
A capsule is conceived as a group of neurons whose outputs encode different properties of an entity such as an object or part of an object in an image. The properties could represent instantiation parameters on the object's appearance manifold like the precise pose, lighting and deformation or the probability that the entity is present. Layers within a capsule network consist of several capsules. Routing between the layers is determined by the votes from the capsules in the lower layer. Capsules can make a guess as to what they expect the higher layer's capsules instantiation parameters to be and cast a vote. Votes are calculated by applying discriminatively learned transformations to a capsule's neuron's outputs. The routing algorithm will then determine, based on the lower capsules' votes, which higher layer capsules to activate. The goal of capsules is to achieve invariance in the presence probability of the object they represent regarding the object's instantiation parameters. A specific capsule architecture is largely defined by the nature of its routing algorithm and the dimension of its output as well as the order of the tensors used to compute the votes.

\section{Transforming Auto-encoders}
The first publication on capsules came from Hinton et al. in the form of transforming auto-encoders in 2011 \cite{hinton2011transforming}. These capsules encode the instantiation parameters of their internal representation together with the probability that the learned entity is present into a small output vector. Each capsule would learn to recognize a single visual entity over a limited subdomain of its appearance manifold. Ideally, the probability would be locally invariant as long as the instantiation parameters remain within the trained submanifold. This is in contrast to the instantiation parameters, which are equivariant. Meaning as the viewing conditions change, the parameters encoding the appearance change by an equal amount.
The transforming auto-encoders introduced by Hinton et al. in 2011 were already motivated by a desire to retain precise part-whole relationships, which are lost by the pooling operations in convolutional neural networks (cf. section \ref{section:limitations}). If a capsule can be trained to encode the pose of the visual entity it represents in its output vector, it is a simple matter to test whether two capsules $A$ and $B$ agree about a higher-level capsule $C$. To see this, suppose that the matrix $\vb{T}_{A/B}$ is the pose between the canonical entity as learned by the capsule $A$ or $B$ respectively and the current instantiation. Multiplying this with the part-whole transformation matrix $\vb{T}_{A/B\rightarrow C}$ will result in a prediction for the pose of capsule $C$'s entity. Now, if
\begin{align}
    \vb{T}_A\vb{T}_{A\rightarrow C} \approx \vb{T}_B\vb{T}_{B\rightarrow C},
\end{align}
then the capsules are a close match and activate capsule $C$. Hinton et al. argue that this naturally leads to precise part-whole relationships. If the entities of capsules $A$ and $B$ e.g. correspond to a mouth and a nose respectively, then they have to be in right spatial relationship to form a face if they activate the higher capsule $C$ representing the whole face. The pose of capsule $C$ can then be determined by the average of the lower capsules' votes.
\begin{align}
    \vb{T_C} = \sum_{i\in \{A, B\}} \vb{T}_i\vb{T}_{i\rightarrow C}
\end{align}
This means that except for the first layer of capsules, only the viewpoint invariant part-whole transformations have to be learned, while the entity poses are encoded in the neural activities at run time. The rest of the paper focuses on how to extract the poses from the pixel intensities for the first layer. This is done by training capsules on transformed image pairs and providing the capsules with non-visual access to the transformation. Hinton et al. justified this by pointing out that the human visual system is also provided with information about the eye-movement while saccades correspond to a translational transformation of the retinal image. 
These first capsule networks actually consist of only one layer of capsules and do not include the routing mechanism of later implementations. Instead, they include two internal layers of logistic neurons, termed recognition and generation units respectively (cf. figure \ref{fig:auto-encoders}). The recognition units are trained to extract pose parameters and the probability that the visual entity is present directly from the provided image.
\begin{figure}[H]
    \centering
    \includegraphics[width=.69\textwidth]{figures/caps-fig1.pdf}
\caption[Capsules in a transforming auto-encoders]{Capsules in a transforming auto-encoder \cite{hinton2011transforming}. The network consists of a single layer of capsules. Each capsule includes hidden recognition (in red) and generation units (in green). During training transformation parameters (in this case the translations $\Delta x$ and $\Delta y$) as well as the transformed image are provided to the network. A capsule's output vector is further multiplied with its probability, thus muting capsules with a low probability.}\label{fig:auto-encoders}
\end{figure}\noindent
A capsule's input can be constrained to a fixed receptive field with the capsules aligned in a grid across the image. The capsules then apply a transformation to the pose and provide the generation units with this information. The generation units on the other hand are trained to output the transformed part of the input image centered at the capsule's receptive field. All the neurons within a capsule are trained discriminatively using gradient descent with backpropagation. The training signal is provided by a form of reconstruction loss where the capsules have access to the transformation and the input and reconstruction target are the original and transformed images respectively. Transforming auto-encoders are able to learn poses in the form of $3x3$ matrices and can be used to successfully apply affine transformations to input images once trained. However, they are limited to one layer of capsules and cannot be scaled effectively, as the capsules are fixed to a single position, compared to the shared weights of moving filters in convolutional layers. Also, they are only able to learn properties, that can be controlled and provided in explicit non-visual form to the network.
\section{Dynamic Routing Between Capsules}\label{sec:dynamic-routing}
In 2017 Sabour et al. extended upon the transforming auto-encoders by suggesting a dynamic routing algorithm for capsules \cite{sabour2017dynamic}. While the benefit of dynamic routing between capsule layers in regard to part-whole relationships was already elaborated upon by Hinton et al., Sabour et al. also motivated the mechanism biologically. They pointed out that human vision ignores irrelevant details by focusing attention on salient features in a sequence of fixations and only ever processes a fraction of the optic array at the highest resolution. They assumed that with a single fixation, groups of activated neurons build a tree structure within the fixed multi-layer visual system. The paper suggests implementing the nodes of this image parse tree as active capsules and have each capsule choose their parent node based on the routing algorithm. As with the capsules of transforming auto encoders, the capsule's neurons should learn to represent various instantiation parameters such as pose, deformation, velocity, albedo, hue, texture, etc. However, the probability of the instance's presence is encoded in the length of a vector of instantiation parameters. A nonlinearity is applied to the output vector in order to keep the length from exceeding $\num{1}$, while keeping the orientation unchanged.
\begin{align}
    \vb{u}_j = \frac{\norm{\vb{s}_j}^2}{1+\norm{\vb{s}_j}^2}\frac{\vb{s}_j}{\norm{\vb{s}_j}}
    \label{eq:squash}
\end{align}
With $\vb{u}_j$ the output vector of capsule $j$ and $\vb{s}_j$ the sum of its inputs. This \emph{squashing} function will reduce short vectors to almost length zero and squash long vectors to a length slightly below 1. For every capsule $j$ that is not a first layer capsule, the input $\vb{s}_j$ is computed from the votes of the lower level capsules.
\begin{align}
    \vb{s}_j = \sum_i c_{ij} \vb{\hat{u}}_{j|i}
\end{align}
Where $\vb{\hat{u}}_{j|i}$ is the lower capsule $i$'s guess for the higher capsule $j$'s instantiation vector. Votes are calculated by applying a transformation matrix $\vb{W}_{ij}$ on a capsule's output vector, as was suggested by Hinton et al. for transforming auto-encoders.
\begin{align}
    \vb{\hat{u}}_{j|i} = \vb{W}_{ij}\vb{u}_i
\end{align}
In this scheme, so far only the part-whole transformation matrices $\vb{W}_{ij}$ have to be learned. The coupling coefficients $c_{ij}$ for a lower capsule $i$ sum to 1. They describe the influence a vote from capsule $i$ has over capsule $j$ and are iteratively fine-tuned by the routing algorithm during the network's forward pass. For the first iteration, the coupling coefficients are computed as a softmax function over the log prior coupling logits $b_{ij}$.
\begin{align}
    c_{ij} = \frac{\exp(b_{ij})}{\sum_k \exp(b_{ik})}
    \label{eq:coupling-coeff}
\end{align}
The $b_{ij}$ can be trained discriminatively along with the other parameters. But it was found that the priors have little influence over the routing algorithm.
Using a vector as capsule output allows the use of a powerful dynamic routing-by-agreement algorithm. The agreement between capsule $i$ and each possible parent $j$ is calculated using the scalar product of the lower capsule's vote and the higher capsule's current output.
\begin{align}
    a_{ij} = \vb{u}_j^T \vb{\hat{u}}_{j|i}
\end{align}
If the scalar product is large, it induces top-down feedback, increasing the coupling coefficient between the two capsules by adding the agreement to the coupling logit $b_{ij}$ (cf. algorithm \ref{alg:routing-by-agreement}).
\begin{algorithm}[H]
\caption[Dynamic routing-by-agreement]{Dynamic routing-by-agreement. Agreement between a lower capsule's vote and the higher capsule's current output is measured by their scalar product. The current output is a weighted average of the lower capsules' votes and updated each iteration.}\label{alg:routing-by-agreement}
\begin{algorithmic}[1]
\Procedure{Routing}{$\vb{\hat{u}}_{j|i},r,l$}
\ForAll{$i \in \Omega_l$}
\Comment{$\Omega_l$ is the set of all capsules in layer $l$}
  \ForAll{$j \in \Omega_{l+1}$}
    \State{$b_{ij}\gets 0$}
  \EndFor
\EndFor
\For{$r$ iterations}
  \ForAll{$i \in \Omega_l$}
    \State{$\vb{c}_i \gets \operatorname{softmax}\qty(\vb{b}_i)$}
    \Comment{computes equation \ref{eq:coupling-coeff}}
  \EndFor
  \ForAll{$j \in \Omega_{l+1}$}
    \State{$\vb{s}_j \gets \sum_i c_{ij} \vb{\hat{u}}_{j|i}$}
    \State{$\vb{u}_j \gets \operatorname{squash}\qty(\vb{s}_j)$}
    \Comment{computes equation \ref{eq:squash}}
  \EndFor
  \ForAll{$i \in \Omega_l$}
    \ForAll{$j \in \Omega_{l+1}$}
      \State{$b_{ij} \gets b_{ij} + \vb{u}_j^T \vb{\hat{u}}_{j|i}$}
    \EndFor
  \EndFor
\EndFor
\State\Return{$\vb{u}_j$}
\EndProcedure
\end{algorithmic}
\end{algorithm}
\noindent
As the lower capsule's coupling coefficients are computed as a softmax of the logits, this will simultaneously decrease all the other couplings. Seeing how the internal representation, the votes and the agreement are all vectors, this type of architecture will be referred to as \emph{vector capsules} for the remainder of this thesis. Sabour et al. further improved upon transforming auto-encoders by developing convolutional capsule layers. This allows them to use learned features all across the image without losing whole-part relationships. They achieve this by having each capsule of a convolutional layer put out a local grid of vectors for each type of capsule in the higher level, where every position on the grid and type of layer is assigned a different part-whole transformation matrix. A capsule's type within a convolutional layer is analogous to the use of different kernels or filters in CNNs (cf. section \ref{section:cnn}). The resulting map of capsule activities i.e. the lengths of the output vectors, can be thought of as a feature map. While this is not strictly convolution, the net effect is the same. Capsules in a convolutional layer possess a receptive field that gets wider the higher up the layer is in the network's topology. For low level capsules, positional information is encoded in the capsule's position within the feature map. The higher up a convolutional capsule is, the smaller the feature map becomes and information on position gets encoded more and more in the instantiation parameter vector.
The primary capsules i.e. the first capsule layer computes its input vectors from the reshaped output of a standard convolutional layer. For the next capsule layers, the routing algorithm is applied. This is yet another improvement over transforming auto-encoders, as the network can be trained on images only without needing access to the applied transformations. The final capsule layer is fully connected and includes one capsule per class (cf. figure \ref{fig:vector-capsules}).
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/vector-capsules.png}
\caption[Vector capsule network with 3 layers]{Vector capsule network with 3 layers \cite{sabour2017dynamic}. Conv1 is a standard convolutional layer consisting of $\num{256}$ $9\cross9$ kernels that learn basic features from pixel intensities, that are converted to 8D vector representations by the primary capsule layer. The primary capsule layer is the only convolutional capsule layer in the network and has 32 types of capsules of which each has a receptive field of the size $9\cross9$ and a stride of $\num{2}$. The class capsule layer (here referred to as DigitCaps) uses 16D vectors and $\num{10}$ fully connected capsules. Note that the routing algorithm is applied only between the primary and the class capsule layer.}\label{fig:vector-capsules}
\end{figure}\noindent
\emph{Margin loss} is used to compute the error signal based on the class capsules' output vector length. For each class a loss $L_k$ is introduced so as to allow multiple object instances of different classes. This is done to make it possible to train the network to segment highly overlapping objects.
\begin{align}
    L_k = T_k \operatorname{max}\qty(0,m^+ - \norm{\vb{v}_k})^2 + \lambda \qty(1-T_k) \operatorname{max}\qty(0, \norm{\vb{v}_k}-m^-)^2
\end{align}
Where $\vb{T} = (0,...,1,...0)^T$ is a one-hot encoded vector of the true class labels and $\lambda = 0.5$ is used to down-weigh the loss for absent classes so that the vectors don't become too short during initial training. In addition, Sabour et al. used a reconstruction loss not unlike with transforming auto-encoders in order to encourage the class capsules to encode useful instantiation parameters for each class. This is done by masking out all but the correct class capsule during training and feeding its output vector to a 3-layer decoder (cf. figure \ref{fig:vector-capsules-reconstr}). The reconstruction loss is calculated as the Euclidean distance between the decoder's output and the input image and scaled down so as not to dominate the margin loss.
\begin{figure}[H]
    \centering
    \includegraphics[width=.9\textwidth]{figures/vector-capsules-reconstr.png}
\caption[Decoder on top of a class vector capsule layer]{Decoder on top of a class vector capsule layer \cite{sabour2017dynamic}. The $16D$ output vector of the correct class capsule is used as input for a 3-layer fully connected decoder while the output of the other capsules is masked. By reconstructing the input image based on the output vector the class capsules are encouraged to encode useful instantiation parameters.}\label{fig:vector-capsules-reconstr}
\end{figure}\noindent
After the network has been trained, the decoder can be used to inspect the instantiation parameters learned by the class capsules. To do this, for a single input image, each dimension of the correct class capsule's output vector is varied and the effect on the reconstructed image is observed.
\begin{figure}[H]
    \centering
    \includegraphics[width=.90\textwidth]{figures/vector-capsules-parameters.pdf}
\caption[Instantiation parameters learned by a vector capsule network on MNIST]{Instantiation parameters learned by a vector capsule network on MNIST \cite{sabour2017dynamic}. The decoder of a trained vector capsule network is used to reconstruct an input image. By perturbing each dimension of the class capsule, sensible instantiation parameters are found to be encoded within the capsule. In this example the shown dimensions where incremented by $\num{.05}$ on the interval $[\num{-0.25}, \num{0.25}]$ around the base values. Note the continuous distribution of the parameters. This is similar to the latent space of variational auto-encoders \cite{kingma2013auto} }\label{fig:vector-capsules-parameters}
\end{figure}\noindent
Sabour et al. were able to demonstrate that a shallow network with only two capsule layers can already achieve good results in object recognition tasks and that the class capsules encode sensible instantiation parameters like the thickness of strokes in case of the MNIST\footnote{Available at \url{http://yann.lecun.com/exdb/mnist/}} dataset (cf. figure \ref{fig:vector-capsules-parameters}). The biological plausibility of vector capsules was further demonstrated by their ability to effectively explain-away regions of overlap so as to successfully segment highly overlapping objects.
\section{Matrix Capsules with EM Routing}\label{sec:matrix-capsules}
The most recent update on capsules came from Hinton et al. in 2018. They pointed out several shortcomings of vector capsules, that they intended to overcome, including \cite{hinton2018matrix}:
\begin{enumerate}
    \item While routing based on agreement is motivated by an assumed parse tree like structure of grouped neurons in the human visual system \cite{hinton2000learning}, the choice to encode the probability that an object is present in the length of a capsule's output vector requires an unprincipled nonlinearity (cf. equation \ref{eq:squash}) that precludes the dynamic routing-by-agreement algorithm from minimizing a sensible objective function. This in turn reduces the overall biological plausibility of the vector capsules introduced by Sabour et al. in 2017.
    \item Dynamic routing-by-agreement has difficulty differentiating between good and very good clusters of votes as the scalar product used to determine the agreement effectively computes the cosine of two angles -- a function that saturates around 1.
    \item Using an $n$-dimensional vector as the internal representation rather than a matrix with $n$ elements requires a part-whole transformation matrix with $n^2$ weights compared to $n$ for matrix-representation.
\end{enumerate}
Compared to vector capsules, the internal representation of matrix capsules is separated into a $4\cross 4$ pose matrix $\vb*{\mu}$ and the object presence probability $a$. This means that the part-whole transformation matrices between all capsule layers are also of size $4\cross 4$. The vote $\vb{V}_{ij}$ between a lower capsule $i$ and a higher capsule $j$ is computed as a matrix multiply.
\begin{align}
    \vb{V}_{ij} = \vb*{\mu}_i \vb{W}_{ij}
\end{align}
Primary capsules again receive their activity and instantiation parameters from a standard convolutional layer (cf. section \ref{sec:dynamic-routing}). The activities of all other consecutive capsule layers are determined by the routing algorithm. Routing between matrix-capsules is based on an Expectation-Maximization (EM) algorithm fitting a gaussian mixture model, where the higher capsules are interpreted as gaussian distributions while the vectorized pose matrices of the lower capsules constitute the data points. EM algorithms are commonly used in statistics and machine learning in order to estimate latent parameters of distributions. They alternate between iteratively computing a log-likelihood function using the current estimation of the parameters in the expectation step and computing parameters maximizing the same log-likelihood function in the following maximization step \cite{dempster1977maximum}. The use of an EM algorithm as a routing mechanism can be thought of as a clustering of lower capsules' votes -- each cluster activating a higher capsule. A fixed cost of $-\beta_u$ must be paid per data point assigned to a capsule if that capsule is not activated. Formally, this cost is the negative log probability density of seeing a data point under an improper uniform prior. On the other hand, if a capsule gets activated, a fixed cost $-\beta_a$ must the paid for coding its mean and variance as well as additional costs for seeing each assigned data point under the distribution given by the activated capsule. Technically, the active capsule's prediction of seeing a data point should be computed in the lower capsule's pose space using the inverse of the part-whole transformation matrix. Hinton et al. use the probability of the data point's vote under the assigned capsule as a computationally low-cost estimate instead. These costs are motivated by a concept from information theory called the minimum description length principle. It states that the best hypothesis for a given dataset is the one with the best coding i.e. the highest compression of the data \cite{rissanen1978modeling}. The difference in cost (penalizing lengthy description) between activating a capsule and not activating it is used to calculate the higher capsules' activation probabilities.\newpage\noindent
The probability of seeing data point $i$ under active capsule $j$'s gaussian with mean $\vb*{\mu}_j$ and axis aligned covariance matrix can be computed for each component $h$ of $i$'s vote $\vb{V}_{ij}$.
\begin{align}
    P_{i|j}^h &= \frac{1}{\sqrt{2\pi\qty(\sigma_j^h)^2}}\exp(-\frac{\qty(V_{ij}^h-\mu_j^h)^2}{2\qty(\sigma_j^h)^2})
\end{align}
And its negative log-likelihood can be written as
\begin{align}
    -\ln(P_{i|j}^h) &= \frac{ln(2\pi)}{2}+\ln(\sigma_j^h)+\frac{\qty(V_{ij}^h-\mu_j^h)^2}{2\qty(\sigma_j^h)^2}.
\end{align}
The total cost of explaining the assigned data points of an activated capsule $j$ per dimension $h$ can then be computed as the sum over all the assigned lower capsules' negative log-likelihoods weighed by the coupling coefficients or assignment probabilities $R_{ij}$.
\begin{align}
    cost_j^h &= - \sum_i R_{ij} \ln(P_{i|j}^h)\\
    &= \qty(\frac{ln(2\pi)}{2}+\ln(\sigma_j^h))\sum_i R_{ij}+\sum_i\frac{R_{ij}\qty(V_{ij}^h-\mu_j^h)^2}{2\qty(\sigma_j^h)^2}\\
    &= \qty(\frac{\ln(2\pi)}{2}+\ln(\sigma_j^h) + \frac{1}{2})\sum_i R_{ij}
\end{align}
Where in the last step the definition of covariance $\qty(\vb*{\sigma}_j)^2$ was used with $p_{i\in\Omega_l}$ the prior probability density over the lower capsules' assignment to higher capsule $j$.
\begin{align}
    \qty(\sigma_j^h)^2 = \sum_i p_i\qty(V_{ij}^h-\mu_j^h)^2 = \sum_i\frac{R_{ij} \qty(V_{ij}^h-\mu_j^h)^2}{\sum_i R_{ij}}
\end{align}
Finally the activation probability of the higher capsule $j$ can be computed as the logistic function applied to the difference of the activation costs.
\begin{align}\label{eq:matrix-logistic}
    a_j &= \operatorname{logistic}\qty(\lambda\qty(\beta_a-\beta_u\sum_i R_{ij}-\sum_h cost_j^h))
\end{align}
The fixed costs (over the course of a forward pass) $\beta_a$ and $\beta_u$ can be learned discriminatively. Hinton et al. suggested using a fixed schedule for the inverse temperature parameter $\lambda$. $\lambda$ is called an inverse temperature based on the fact that the logistic function\label{foot:fermi-dirac} has the same \enquote{S} shape as the Fermi-Dirac (FD) distribution used in quantum statistics to describe the distribution of energy states in a fermionic ensemble. In a FD distribution, the inverse of the absolute temperature defines the steepness of the curve. Here, the use of $\lambda$ in the logistic function is analogous to the inverse of the temperature.
Using an EM algorithm for routing and the logistic function to compute the activation probabilities can be motivated by interpreting the network as a physical system with the description cost as the system's energy. In thermodynamics a quantity called \emph{free energy} is defined as the difference between the expected energy and the entropy of a system. Minimizing free energy is then achieved by finding the optimal trade-off between minimizing the expected energy while maximizing the entropy. In the context of this analogy, the logistic function then computes the distribution over the difference in energies for activating a capsule, thereby minimizing the system's free energy. In the EM algorithm's M-step the expected energy (i.e. the part of the activation cost paid for explaining the data points) is minimized by estimating the distribution's mean and variance using the fixed assignment probabilities (thereby leaving the entropy unchanged). During the following E-step the assignment probabilities are computed using the softmax function, again minimizing the free energy. This can be seen by treating the logits as negative energies $E_i$. The softmax function is proportional to $\exp(-E_i)$, which in physics is known as the Boltzmann distribution. The Boltzmann distribution can be shown to minimize free energy. The objective function minimized by the EM routing algorithm (cf. algorithm \ref{alg:em-routing}) is then the sum of the activation cost, negative entropy of the activations and assignment probabilities during the E-step and the expected energy.
\begin{align}
    L\qty(\vb{a}, \vb{R}) =& \sum_{j\in\Omega_{l+1}}a_j\qty(-\beta_a)+a_j \ln(a_j)+(1-a_j)\ln(1-a_j)\\
    &+\beta_u\sum_{i\in\Omega_l}R_{ij}+\sum_{i\in\Omega_l}a_i R_{ij}\ln(R_{ij})\\
    &+\sum_h cost_j^h\label{eq:objective-function}
\end{align}
Overall, all three steps can be shown to minimize the same free energy, greatly supporting the biological plausibility of the proposed system \cite{lecun2006tutorial}. Another argument can be made for the plausibility of using a softmax in the routing procedure. Computing the assignment probabilities as a softmax over the higher-level capsules effectively means that the top-down feedback from very active capsules can inhibit other nearby capsules whose receptive fields overlap. This is not unlike the competition of neurons in a winner-take-all circuit, designed to model decision-making and attention mechanisms in the brain \cite{lee1999attention}.
\begin{algorithm}
\caption[Expectation-Maximization routing for matrix capsules]{Expectation-Maximization routing for matrix capsules. The routing procedure acts between two capsule layers, where the lower level's activities and pose matrices have already been determined. The algorithm can be interpreted as a form of high-dimensional coincidence filtering. A higher-level capsule is activated by the agreement of the votes from a lower level cluster of capsules transformed into its pose space.}\label{alg:em-routing}
\begin{algorithmic}[1]
\Procedure{EM-Routing}{$\vb{a},\vb{V},r,l$}
    \ForAll{$i \in \Omega_l$}
        \ForAll{$j \in \Omega_{l+1}$}
            \State{$R_{ij} \gets \frac{1}{\abs{\Omega_{l+1}}}$}
        \EndFor
    \EndFor
    \For{$r$ iterations}
        \ForAll{$j \in \Omega_{l+1}$}
            \State\Call{M-Step}{$\vb{a}.\vb{R},\vb{V},j$}
        \EndFor
        \ForAll{$i \in \Omega_l$}
            \State\Call{E-Step}{$\vb*{\mu},\vb*{\sigma},\vb{a},\vb{V},i$}
        \EndFor
    \EndFor
    \State\Return{$\vb{a},\vb*{\mu}$}
\EndProcedure
\Procedure{M-Step}{$\vb{a},\vb{R},\vb{V},j$}
    \ForAll{$i \in \Omega_l$}
        \State{$R_{ij}\gets R_{ij}a_i$}
    \EndFor
    \For{$h\gets 1$ \textbf{to} $H$}
        \State $\mu_{j}^h \gets \frac{\sum_i R_{ij} V_{ij}h}{\sum_i R_{ij}}$
        \State $\qty(\sigma_j^h)^2 \gets \frac{\sum_i R_{ij} \qty(V_{ij}^h-\mu_j^h)^2}{\sum_i R_{ij}}$
        \State $cost^h \gets \qty(\beta_u + \log(\sigma_j^h))\sum_i R_{ij}$
    \EndFor
    \State $a_j \gets \operatorname{logistic}\qty(\lambda\qty(\beta_a - \sum_h cost^h))$
    \State\Return{$\vb*{\mu}_j,\vb*{\sigma}_j$}
\EndProcedure
\Procedure{E-Step}{$\vb*{\mu},\vb*{\sigma},\vb{a},\vb{V},i$}
    \ForAll{$j \in \Omega_{l+1}$}
        \State $p_j \gets \frac{1}{\prod_h^H 2\pi \qty(\sigma_j^h)^2}\exp(-\sum_h^H\frac{\qty(V_{ij}^h-\mu_j^h)^2}{2\qty(\sigma_j^h)^2})$
        \State $R_{ij} \gets \frac{\exp(a_j p_j)}{\sum_{k\in\Omega_{l+1}} \exp(a_k p_k)}$
        \State\Return{$\vb{R}$}
    \EndFor
\EndProcedure
\end{algorithmic}
\end{algorithm}
\noindent
Matrix capsule networks include convolutional capsule layers. This is implemented in the EM routing algorithm, simply by restricting assignments between lower and higher-level capsules to the higher-level capsule's receptive field. The learned whole-part transformation matrices for a capsule type are then shared across all positions (like weight-sharing in CNNs). This makes it possible to use different kernel-sizes and strides, allowing for more complex and fine-tuned network topologies. 
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/matrix-capsules.png}
\caption[Multi-layer matrix capsule network]{Multi-layer matrix capsule network \cite{hinton2018matrix}. The standard convolutional layer has $A$ filters, while the 4 capsule layers consist of $B,C,D$ and $E$ types of capsules respectively. Between two capsule layers, the number of weights is given by the product of the size of the receptive field ($K\cross K$ for the convolutional capsules, $1\cross 1$ for the class capsules), the number of capsule types of both layers and the size of the pose matrix ($4\cross 4$). This means in this network for example, the routing mechanism has to determine $K\cross K\cross B\cross C$ activation probabilities and pose matrices between the primary and the first convolutional capsule layer.}\label{fig:matrix-capsules}
\end{figure}\noindent
For the final layer, there is again one fully connected capsule per class, like for the vector capsule networks (cf. figure \ref{fig:matrix-capsules}). However, the class capsules are connected differently. So as not to lose positional information, the coordinates of the center of the active capsule's receptive field on the grid are added to its vote matrix. By doing this, all the capsules of a type in the second to last layer share the same whole-part transformation matrix and at the same time pass information on their position to the final layer of class capsules. This technique is referred to as \emph{Coordinate Addition} by Hinton et al.
A new loss function called \emph{spread loss} is introduced to train directly on the class capsules' activities, without any reconstruction.
\begin{align}\label{eq:spread-loss}
    L_i &= \qty(\max(0,m-\qty(a_t-a_i)))^2
\end{align}
With $a_t$ the correct class activity. Compared to earlier versions of capsule networks, no effort is made to encourage the final layer of capsules to encode instantiation parameters useful for reconstructing a transformed version of the input image. Instead they are left to learn whatever increases their classification accuracy. Spread loss effectively penalizes activities that are further than the $margin$ from the target activity. The margin can be increased on a linear schedule during training so as to avoid the capsules from dying early. Hinton et al. were able to demonstrate that their matrix capsules could achieve similar performance to CNNs with fewer learnable weights and perform much better than vector capsules on more complex shape-recognition datasets like smallNORB \cite{lecun2004learning}. They are also more robust against adversarial attacks of the \emph{fast gradient sign method} than baseline CNNs and possibly generalize better to novel viewpoints, although the latter could not be conclusively shown.